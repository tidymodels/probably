% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cal-validate.R
\name{cal_validate_isotonic_boot}
\alias{cal_validate_isotonic_boot}
\alias{cal_validate_isotonic_boot.rset}
\title{Measure performance with and without using bagged isotonic regression calibration}
\usage{
cal_validate_isotonic_boot(
  .data,
  truth = NULL,
  estimate = dplyr::starts_with(".pred_"),
  times = 10,
  parameters = NULL,
  metrics = NULL,
  save_details = FALSE,
  summarize = TRUE,
  ...
)

\method{cal_validate_isotonic_boot}{rset}(
  .data,
  truth = NULL,
  estimate = dplyr::starts_with(".pred_"),
  times = 10,
  parameters = NULL,
  metrics = NULL,
  save_details = FALSE,
  summarize = TRUE,
  ...
)
}
\arguments{
\item{.data}{A \code{data.frame} object, or \code{rset} object, that contains
prediction columns.}

\item{truth}{The column identifier for the true class results
(that is a factor). This should be an unquoted column name.}

\item{estimate}{A vector of column identifiers, or one of \code{dplyr} selector
functions to choose which variables contains the class probabilities. It
defaults to the prefix used by tidymodels (\code{.pred_}). The order of the
identifiers will be considered the same as the order of the levels of the
\code{truth} variable.}

\item{times}{Number of bootstraps.}

\item{parameters}{(Optional)  An optional tibble of tuning parameter values
that can be used to filter the predicted values before processing. Applies
only to \code{tune_results} objects.}

\item{metrics}{A set of metrics passed created via \code{yardstick::metric_set()}}

\item{save_details}{Indicates whether to include the \code{calibration} and
\code{validation} columns when the \code{summarize} argument is set to FALSE.}

\item{summarize}{Indicates to pass tibble with the metrics averaged, or
if to return the same sampled object but with new columns containing the
calibration y validation list columns.}

\item{...}{Additional arguments passed to the models or routines used to
calculate the new probabilities.}
}
\description{
This function uses resampling to measure the effect of calibrating predicted
values.
}
\details{
Please note that this function does not apply to \code{tune_result} objects. It
only processes resampled data.

These functions take an resampling object, created via \code{rsample},
and for each resample, it calculates the calibration on the analysis set, and
then applies the calibration on the assessment set.
}
\section{Performance Metrics}{


By default, the average of the Brier scores (classification calibration) or the
root mean squared error (regression) is returned. Any appropriate
\code{\link[yardstick:metric_set]{yardstick::metric_set()}} can be used. The validation function compares the
average of the metrics before, and after the calibration.
}

\examples{

library(dplyr)

segment_logistic \%>\%
  rsample::vfold_cv() \%>\%
  cal_validate_isotonic_boot(Class)

}
