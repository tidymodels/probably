% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cal-validate.R
\name{cal_validate_linear}
\alias{cal_validate_linear}
\alias{cal_validate_linear.rset}
\title{Measure performance with and without using linear regression calibration}
\usage{
cal_validate_linear(
  .data,
  truth = NULL,
  estimate = dplyr::starts_with(".pred"),
  smooth = TRUE,
  parameters = NULL,
  metrics = NULL,
  save_details = FALSE,
  summarize = TRUE,
  ...
)

\method{cal_validate_linear}{rset}(
  .data,
  truth = NULL,
  estimate = dplyr::starts_with(".pred"),
  smooth = TRUE,
  parameters = NULL,
  metrics = NULL,
  save_details = FALSE,
  summarize = TRUE,
  ...
)
}
\arguments{
\item{.data}{A \code{data.frame} object, or \code{tune_results} object, that contains
predictions and probability columns.}

\item{truth}{The column identifier for the true class results
(that is a factor). This should be an unquoted column name.}

\item{estimate}{A vector of column identifiers, or one of \code{dplyr} selector
functions to choose which variables contains the class probabilities. It
defaults to the prefix used by tidymodels (\code{.pred_}). The order of the
identifiers will be considered the same as the order of the levels of the
\code{truth} variable.}

\item{smooth}{Applies to the logistic models. It switches between logistic
spline when \code{TRUE}, and simple logistic regression when \code{FALSE}.}

\item{parameters}{(Optional)  An optional tibble of tuning parameter values
that can be used to filter the predicted values before processing. Applies
only to \code{tune_results} objects.}

\item{metrics}{A set of metrics passed created via \code{yardstick::metric_set()}}

\item{save_details}{Indicates whether to include the \code{calibration} and
\code{validation} columns when the \code{summarize} argument is set to FALSE.}

\item{summarize}{Indicates to pass tibble with the metrics averaged, or
if to return the same sampled object but with new columns containing the
calibration y validation list columns.}

\item{...}{Additional arguments passed to the models or routines used to
calculate the new probabilities.}
}
\description{
Measure performance with and without using linear regression calibration
}
\section{Performance Metrics}{


By default, the average of the root mean square error (RMSE) is returned.
Any appropriate \code{\link[yardstick:metric_set]{yardstick::metric_set()}} can be used. The validation
function compares the average of the metrics before, and after the calibration.
}

\examples{
library(dplyr)
library(yardstick)
library(rsample)

head(boosting_predictions_test)

reg_stats <- metric_set(rmse, ccc)

set.seed(828)
boosting_predictions_oob \%>\%
  # Resample with 10-fold cross-validation
  vfold_cv() \%>\%
  cal_validate_linear(truth = outcome, smooth = FALSE, metrics = reg_stats)
}
\seealso{
\code{\link[=cal_apply]{cal_apply()}}, \code{\link[=cal_estimate_linear]{cal_estimate_linear()}}
}
